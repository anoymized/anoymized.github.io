<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- 描述信息，显示在搜索引擎结果中，可以根据实际内容更改 -->
  <meta name="description"
        content="HuPerFlow: A Comprehensive Benchmark for Human vs. Machine Motion Estimation.">
  <!-- 关键词，用于搜索引擎优化，可根据实际内容调整 -->
  <meta name="keywords" content="Optical flow, Motion Estimation, Human Perception, Dataset, Psychophysics">
  <!-- 视口设置，让页面在移动设备上更好显示 -->
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <!-- 网页标题，将显示在浏览器标签页上，可自定义 -->
  <title>HuPerFlow</title>

  <!-- Google Analytics 跟踪代码，用于网站流量统计 -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <!-- 加载Google字体，可根据需要修改 -->
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <!-- 加载CSS样式文件 -->
  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <!-- 页面图标 -->
  <link rel="icon" href="./static/images/favicon.svg">

  <!-- 加载jQuery和其他JS库 -->
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<!-- 导航栏 -->
<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <!-- 菜单按钮 -->
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <!-- 首页图标，可修改链接 -->
      <a class="navbar-item" href="xxxx">
        <span class="icon">
          <i class="fas fa-home"></i>
        </span>
      </a>

      <!-- 更多研究的下拉菜单 -->
      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">More Research (Not available in anonymous mode) </a>
        <div class="navbar-dropdown">
          <!-- 研究链接，可替换为您的研究项目链接 -->
          <a class="navbar-item" href="xxx">Motion Model</a>
        </div>
      </div>
    </div>
  </div>
</nav>
<!-- 标题和作者信息部分 -->
<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <!-- 主要标题，页面显示的标题，可自定义 -->
          <h1 class="title is-1 publication-title">HuPerFlow: A Comprehensive Benchmark for Human vs. Machine Motion Estimation</h1>
          <div class="is-size-5 publication-authors">
            <!-- 作者名和链接，可修改成实际作者信息 -->
            <span class="author-block">
              <a href="xxx"> Anonymous</a><sup>1</sup>,
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <!-- 作者所属机构信息 -->
            <span class="author-block"><sup>1</sup>Anonymous University1,</span>
            <span class="author-block"><sup>2</sup>Anonymous Research2</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- 论文链接，点击时弹出提示 -->
              <span class="link-block">
                <a href="javascript:void(0);" onclick="showAlert()" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon"><i class="fas fa-file-pdf"></i></span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="javascript:void(0);" onclick="showAlert()" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon"><i class="ai ai-arxiv"></i></span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- 视频链接，点击时弹出提示 -->
              <span class="link-block">
                <a href="javascript:void(0);" onclick="showAlert()" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon"><i class="fab fa-youtube"></i></span>
                  <span>Video</span>
                </a>
              </span>
              <!-- 代码链接，点击时弹出提示 -->
              <span class="link-block">
                <a href="javascript:void(0);" onclick="showAlert()" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon"><i class="fab fa-github"></i></span>
                  <span>Code</span>
                </a>
              </span>
              <!-- 数据集链接，点击时弹出提示 -->
              <span class="link-block">
                <a href="javascript:void(0);" onclick="showAlert()" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon"><i class="far fa-images"></i></span>
                  <span>Data</span>
                </a>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- JavaScript，用于显示提示信息 -->
<script>
  function showAlert() {
    alert("Not available in anonymous mode. All data/code/benchmark will be open once the paper gets accepted.");
  }
</script>



<!-- Teaser 主视频展示 -->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <!-- 主视频展示 -->
      <video id="teaser" autoplay muted loop playsinline width="100%" height="auto">
        <source src="./static/5_Spring_AllOs.mp4" type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
       <span class="dnerf">HuPerFlow</span> collects and analyzes extensive human-perceived optical flow data across multiple established optical flow benchmarks. The video above demonstrates examples from the <a href="https://spring-benchmark.org/">Spring Benchmark</a>. In many cases, human perception of motion (shown by red arrows) differs from the ground truth (blue arrows), with the discrepancy represented by the endpoint error (size of the green circles).

      </h2>
    </div>
  </div>
</section>


<!-- 轮播视频展示 -->
<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <!-- 每个视频项目 -->
        <div class="item">
          <video autoplay controls muted loop playsinline height="100%">
            <source src="./static/1_KITTI_Session5_Mov1.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item">
          <video autoplay controls muted loop playsinline height="100%">
            <source src="./static/2_VirtualKITTI2_Session4_Mov2.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item">
          <video autoplay controls muted loop playsinline height="100%">
            <source src="./static/3_MPI_Sintel_NV_Session4_Mov1.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item">
          <video autoplay controls muted loop playsinline height="100%">
            <source src="./static/4_VIPER_Session7_Mov2.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item">
          <video autoplay controls muted loop playsinline height="100%">
            <source src="./static/5_Spring_Session12_Mov2.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item">
          <video autoplay controls muted loop playsinline height="100%">
            <source src="./static/6_Monkaa_Session4_Mov1.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item">
          <video autoplay controls muted loop playsinline height="100%">
            <source src="./static/7_MHOF_Session7_Mov2.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item">
          <video autoplay controls muted loop playsinline height="100%">
            <source src="./static/8_Driving_Session12_Mov2.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item">
          <video autoplay controls muted loop playsinline height="100%">
            <source src="./static/9_Flyingthings3D_Session9_Mov1.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item">
          <video autoplay controls muted loop playsinline height="100%">
            <source src="./static/10_TartanAir_Session2_Mov2.mp4" type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section>


  <!-- 摘要部分 -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <!-- 论文摘要内容，可以自行替换 -->
          <p>
            There are numerous optical flow datasets and benchmarks with ground truth information; however, studies focusing on human-perceived flow in natural scenes remain underexplored. We introduce HuPerFlow—a benchmark for human-perceived flow derived from ten representative computer vision optical flow datasets encompassing 2,400 probed locations. Through online psychophysical experiments, we collected 38,400 data points (trials) from 480 participant instances. Results showed that human-perceived flow aligned with ground truth in certain spatiotemporal smoothing areas but also revealed systematic errors influenced by different dataset properties. Additionally, we evaluated several optical flow algorithms with human-perceived flow, uncovering similarities as well as unique aspects of human perception in complex natural scenes. HuPerFlow is the first human-perceived flow dataset aimed to bridge the gap between human and machine motion estimation for training and testing. The HuPerFlow benchmark, along with corresponding movies and visualizations, will be available upon acceptance.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>


 
<!-- Teaser 主视频展示 -->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <!-- 主视频展示 -->
      <video id="teaser" autoplay muted loop playsinline width="100%" height="auto">
        <source src="./static/5_Spring_AllOs.mp4" type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
       <span class="dnerf">Several representative computer vision models and human-inspired models for motion estimation were tested on our human benchmark. The red, yellow, and blue arrows represent human perception, computer vision (CV) models, and ground truth (GT), respectively. We introduce the Relative Consistency Index (RCI) to illustrate each model's ability to align with human perception (i.e., human bias that differs from GT). The yellow circle denotes this alignment; a larger circle indicates that the CV model's response is closer to human perception than to GT. Overall, we found that basic human-aligned computations, such as models based on motion energy calculations, capture human illusions of motion more effectively than state-of-the-art CV models.
    
      </h2>
    </div>
  </div>
</section>

  





<!-- 参考文献 BibTeX 格式 -->
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{xxx,
  author    = {xxxx},
  title     = {HuPerFlow: a Human Perceived Flow dataset},
  journal   = {xxx},
  year      = {2025},
}</code></pre>
  </div>
</section>

<!-- 页脚部分 -->
<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <!-- 链接到PDF文件 -->
      <a class="icon-link" href="./static/paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <!-- GitHub图标及链接 -->
      <a class="icon-link" href="xxx" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <!-- 网站许可证信息 -->
          <p>
            This website is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This page is borrowed from <a href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
